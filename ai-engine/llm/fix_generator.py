# ai-engine/llm/fix_generator.py
import os
import json
from typing import Dict, Any
from openai import AzureOpenAI
import subprocess

class FixGenerator:
    """
    Generates auto-remediation code (Terraform, Helm, Bash) using GenAI.
    """
    
    def __init__(self):
        self.client = AzureOpenAI(
            api_key=os.getenv("AZURE_OPENAI_KEY"),
            api_version="2024-02-15-preview",
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT")
        )
        self.deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT", "gpt-4")
    
    async def generate_fix(
        self,
        root_cause: str,
        service_name: str,
        severity: str
    ) -> Dict[str, Any]:
        """
        Generate infrastructure fix code based on root cause.
        """
        
        prompt = self._create_fix_prompt(root_cause, service_name, severity)
        
        response = self.client.chat.completions.create(
            model=self.deployment,
            messages=[
                {
                    "role": "system",
                    "content": self._get_system_prompt()
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.1,  # Low temperature for code generation
            max_tokens=2500,
            response_format={"type": "json_object"}
        )
        
        result = json.loads(response.choices[0].message.content)
        
        return {
            "fix_type": result.get("fix_type"),
            "code": result.get("code"),
            "fix_details": result.get("details"),
            "validation_steps": result.get("validation_steps", []),
            "rollback_plan": result.get("rollback_plan")
        }
    
    def _get_system_prompt(self) -> str:
        """
        System prompt for code generation.
        """
        return """You are an expert DevOps engineer specializing in Infrastructure as Code.

Generate production-ready remediation code for Kubernetes incidents.

You can generate:
1. **Helm values updates** - for resource adjustments, scaling, config changes
2. **Terraform patches** - for infrastructure modifications
3. **Kubectl commands** - for immediate fixes
4. **Bash scripts** - for complex multi-step remediations

Always include:
- Clear comments explaining each step
- Validation commands to verify the fix
- Rollback procedures
- Best practices (gradual rollouts, health checks)

Respond in JSON format:
{
  "fix_type": "helm|terraform|kubectl|bash",
  "code": "The actual code/commands",
  "details": {
    "description": "What this fix does",
    "impact": "Expected impact",
    "estimated_time": "Time to apply"
  },
  "validation_steps": ["step1", "step2"],
  "rollback_plan": "How to revert if needed"
}"""
    
    def _create_fix_prompt(self, root_cause: str, service_name: str, severity: str) -> str:
        """
        Create prompt for fix generation.
        """
        return f"""Generate a remediation fix for the following incident:

**Service**: {service_name}
**Root Cause**: {root_cause}
**Severity**: {severity}

Requirements:
- The fix should be production-safe
- Include proper validation
- Provide rollback instructions
- Use best practices (e.g., rolling updates for Kubernetes)

Generate the appropriate fix in JSON format."""
    
    async def apply_fix(self, incident_id: str, fix_type: str) -> Dict[str, Any]:
        """
        Apply the generated fix to the infrastructure.
        This is a simplified example - in production, this would integrate with
        CI/CD pipelines, GitOps, and approval workflows.
        """
        
        # In production, this would:
        # 1. Create a branch in Git
        # 2. Apply the fix code
        # 3. Run tests
        # 4. Create a PR or auto-merge (based on severity)
        # 5. Trigger deployment pipeline
        
        return {
            "status": "applied",
            "incident_id": incident_id,
            "timestamp": "2024-01-21T14:35:00Z",
            "deployment_id": "deploy-12345"
        }
    
    async def create_pull_request(self, incident_id: str, fix_type: str) -> str:
        """
        Create a GitHub PR with the generated fix.
        """
        # Simplified - in production, use GitHub API
        # Example using subprocess to create git commits
        
        pr_title = f"[Auto-Fix] {incident_id} - {fix_type}"
        pr_body = f"""
## Automated Fix for {incident_id}

This PR was automatically generated by the AI DevOps platform.

### Root Cause
[Populated from incident analysis]

### Fix Applied
[Description of the fix]

### Validation
- [ ] Tests passed in staging
- [ ] No regressions detected
- [ ] Performance metrics stable

### Rollback Plan
[Instructions to rollback if needed]

**Auto-generated by AI DevOps Platform**
        """
        
        # Mock PR URL - in production, this would use GitHub/GitLab API
        return f"https://github.com/org/repo/pull/12345"


# Example fix templates
HELM_FIX_TEMPLATE = """# Helm values update for {service_name}
# Fixes: {root_cause}

resources:
  limits:
    memory: "{new_memory}"
    cpu: "{new_cpu}"
  requests:
    memory: "{req_memory}"
    cpu: "{req_cpu}"

autoscaling:
  enabled: true
  minReplicas: {min_replicas}
  maxReplicas: {max_replicas}
  targetCPUUtilizationPercentage: 70

# Apply with:
# helm upgrade {service_name} ./charts/{service_name} -f values.yaml --namespace production
"""

TERRAFORM_FIX_TEMPLATE = """# Terraform patch for {resource}
# Fixes: {root_cause}

resource "azurerm_kubernetes_cluster_node_pool" "system" {{
  name                  = "system"
  kubernetes_cluster_id = azurerm_kubernetes_cluster.main.id
  vm_size              = "{vm_size}"
  node_count           = {node_count}
  
  tags = {{
    auto_fix = "true"
    incident_id = "{incident_id}"
  }}
}}

# Apply with:
# terraform plan -out=tfplan
# terraform apply tfplan
"""

KUBECTL_FIX_TEMPLATE = """#!/bin/bash
# Emergency fix for {incident_id}
# Root cause: {root_cause}

set -e

echo "Applying emergency fix..."

# Scale up replicas
kubectl scale deployment {service_name} --replicas={replicas} -n production

# Update resource limits
kubectl set resources deployment {service_name} \\
  --limits=cpu={cpu},memory={memory} \\
  --requests=cpu={req_cpu},memory={req_memory} \\
  -n production

# Wait for rollout
kubectl rollout status deployment {service_name} -n production

# Validate
kubectl get pods -n production -l app={service_name}

echo "Fix applied successfully!"
"""


if __name__ == "__main__":
    import asyncio
    
    async def test_generator():
        generator = FixGenerator()
        
        result = await generator.generate_fix(
            root_cause="Memory leak in order-service causing OOMKilled errors",
            service_name="order-service",
            severity="high"
        )
        
        print(json.dumps(result, indent=2))
    
    # asyncio.run(test_generator())